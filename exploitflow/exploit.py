# Copyright 2022 VÃ­ctor Mayoral-Vilches. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# Inspired by https://github.com/tobegit3hub/miniflow

from abc import ABCMeta, abstractmethod
import logging
import math
import os
import sys


from . import graph
from wasabi import color


class Exploit(object):
    """The basic class for all operation."""

    def __init__(self, name="Exploit"):
        self.name = name

    def get_name(self):
        return self.name

    def set_name(self, name):
        self.name = name

    @abstractmethod
    def forward(self):
        # TODO: No need to implement in abstract method
        raise NotImplementedError

    def grad(self):
        raise NotImplementedError

    def __str__(self):
        return str(self.name)

    def __add__(self, other):
        return AddExploit(self, other)

    def __radd__(self, other):
        return self.__add__(other)

    def __sub__(self, other):
        return MinusExploit(self, other)

    def __rsub__(self, other):
        return MinusExploit(other, self)

    def __mul__(self, other):
        return MultipleExploit(self, other)

    def __rmul__(self, other):
        return self.__mul__(other)

    def __div__(self, other):
        return DivideExploit(self, other)

    def __truediv__(self, other):
        return DivideExploit(self, other)

    def __rdiv__(self, other):
        return DivideExploit(other, self)


class PlaceholderExploit(Exploit):
    """The placeholer operation which value is set when Flow.run()"""

    def __init__(self, dtype=None, shape=None, name="Placeholder"):
        super(PlaceholderExploit, self).__init__(name)
        # TODO: Use dtype and shape
        self._dtype = dtype
        self._shape = shape

        # The value is None util Flow.run() with feed_dict parameter
        self._value = None

        # TODO: Support other graph instance
        self._graph = graph.get_default_graph()
        self._graph.add_to_graph(self)

    def set_value(self, value):
        self._value = value

    def get_value(self):
        return self._value

    def forward(self):
        if self._value is None:
            return ""
        else:
            return self._value

    def grad(self, partial_derivative_opname=None):
        return 0


class ConstantExploit(Exploit):
    """The constant operation which contains one initialized value."""

    def __init__(self, value, name="Constant"):
        super(ConstantExploit, self).__init__(name)
        self._value = value

        self._graph = graph.get_default_graph()
        self._graph.add_to_graph(self)

    # TODO: Not allow to set the value

    def get_value(self):
        return self._value

    def forward(self):
        # # debug
        # print(
        #     color(
        #         "Executing " + self.get_name() + ": " + str(self._value),
        #         fg="white",
        #         bg="green",
        #         bold=True,
        #     )
        # )
        return self._value

    def grad(self, partial_derivative_opname=None):
        return 0


class VariableExploit(Exploit):
    """
    The variable operation which contains one variable. The variable may be
    trainable or not-trainable. This is used to define the machine learning
    models.
    """

    def __init__(self, value, is_trainable=True, name="Variable"):
        super(VariableExploit, self).__init__(name)
        self._value = value
        self._is_trainable = is_trainable

        self._graph = graph.get_default_graph()
        self._graph.add_to_graph(self)

        if self._is_trainable:
            self._graph.add_to_trainable_variables_collection(self.get_name(), self)

    def get_value(self):
        return self._value

    def set_value(self, value):
        self._value = value

    def forward(self):
        return self._value

    def grad(self, partial_derivative_opname=None):
        if (
            partial_derivative_opname is not None
            and self.name == partial_derivative_opname
            or partial_derivative_opname is None
        ):
            # Specify to compute this derivative
            return 1
        else:
            # Specify to compute other derivative
            return 0


class AddExploit(Exploit):
    """
    The addition operation which has only two inputs. The input can be
    primitive, ConstantExploit, PlaceholerExploit, VariableExploit or other ops.
    """

    def __init__(self, input1, input2, name="Add"):
        super(AddExploit, self).__init__(name)
        self._op1 = (
            ConstantExploit(input1) if not isinstance(input1, Exploit) else input1
        )
        self._op2 = (
            ConstantExploit(input2) if not isinstance(input2, Exploit) else input2
        )
        self._graph = graph.get_default_graph()
        self._graph.add_to_graph(self)

    def forward(self):
        result = self._op1.forward() + self._op2.forward()
        self._graph.add_edge(self._op1, self._op2)  # edge between ops
        self._graph.add_edge(self._op2, self)  # edge between second op and addition
        # # debug
        # print(
        #     color(
        #         "Executing "
        #         + str(self.get_name())
        #         + " with "
        #         + str(self._op1)
        #         + " (op1) and "
        #         + str(self._op2)
        #         + " (op2).",
        #         fg="white",
        #         bg="green",
        #         bold=True,
        #     )
        # )
        return result

    def grad(self, partial_derivative_opname=None):
        return self._op1.grad(partial_derivative_opname) + self._op2.grad(
            partial_derivative_opname
        )


class MinusExploit(Exploit):
    """
    The minus operation.
    """

    def __init__(self, input1, input2, name="Minus"):
        super(MinusExploit, self).__init__(name)

        if not isinstance(input1, Exploit):
            self._op1 = ConstantExploit(input1)
        else:
            self._op1 = input1

        if not isinstance(input2, Exploit):
            self._op2 = ConstantExploit(input2)
        else:
            self._op2 = input2

        self._graph = graph.get_default_graph()
        self._graph.add_to_graph(self)

    def forward(self):
        return self._op1.forward() - self._op2.forward()

    def grad(self, partial_derivative_opname=None):
        return self._op1.grad(partial_derivative_opname) - self._op2.grad(
            partial_derivative_opname
        )


class MultipleExploit(Exploit):
    def __init__(self, input1, input2, name="Multiple"):
        super(MultipleExploit, self).__init__(name)

        if not isinstance(input1, Exploit):
            self._op1 = ConstantExploit(input1)
        else:
            self._op1 = input1

        if not isinstance(input2, Exploit):
            self._op2 = ConstantExploit(input2)
        else:
            self._op2 = input2

        self._graph = graph.get_default_graph()
        self._graph.add_to_graph(self)

    def forward(self):
        return self._op1.forward() * self._op2.forward()

    def grad(self, partial_derivative_opname=None):
        op1_value = self._op1.forward()
        op2_value = self._op2.forward()

        if isinstance(self._op1, (PlaceholderExploit, ConstantExploit)):
            # op1 is the coefficient of this formula
            op1_grad = self._op1.forward()

            if isinstance(self._op2, (PlaceholderExploit, ConstantExploit)):
                # two elements are both constant values
                op2_grad = 0
            else:
                # op2 may has VariableExploit
                op2_grad = self._op2.grad(partial_derivative_opname)

            return op1_grad * op2_grad
        elif isinstance(self._op2, (PlaceholderExploit, ConstantExploit)):
            # op2 is the coefficient of this formula
            op2_grad = self._op2.forward()

            # op1 may has VariableExploit
            op1_grad = self._op1.grad(partial_derivative_opname)

            return op1_grad * op2_grad
        else:
            # op1 and op2 may has VariableExploit
            # Refer to https://en.wikipedia.org/wiki/Product_rule
            # logging.error(
            #    "Not support complex formula which has multiple VariableExploit")
            # raise NotImplementedError

            op1_grad = self._op1.grad(partial_derivative_opname)
            op2_grad = self._op2.grad(partial_derivative_opname)
            return op1_grad * op2_value + op1_value * op2_grad


class DivideExploit(Exploit):
    def __init__(self, input1, input2, name="Divide"):
        super(DivideExploit, self).__init__(name)

        if not isinstance(input1, Exploit):
            self._op1 = ConstantExploit(input1)
        else:
            self._op1 = input1

        if not isinstance(input2, Exploit):
            self._op2 = ConstantExploit(input2)
        else:
            self._op2 = input2

        self._graph = graph.get_default_graph()
        self._graph.add_to_graph(self)

    def forward(self):
        return self._op1.forward() / self._op2.forward()

    def grad(self, partial_derivative_opname=None):
        op1_value = self._op1.forward()
        op2_value = self._op2.forward()

        if isinstance(self._op1, (PlaceholderExploit, ConstantExploit)):
            # op1 is the coefficient of this formula
            op1_grad = self._op1.forward()

            if isinstance(self._op2, (PlaceholderExploit, ConstantExploit)):
                # two elements are both constant values
                op2_grad = 0
            else:
                # op2 may has VariableExploit
                op2_grad = self._op2.grad(partial_derivative_opname)

            # Reciprocal rule, refer to https://en.wikipedia.org/wiki/Reciprocal_rule
            # import ipdb;ipdb.set_trace()
            result = self._op1.forward() * -float(op2_grad) / math.pow(op2_value, 2)
        elif isinstance(self._op2, (PlaceholderExploit, ConstantExploit)):
            # op2 is the coefficient of this formula
            op2_grad = self._op2.forward()

            # op1 may has VariableExploit
            op1_grad = self._op1.grad(partial_derivative_opname)
            result = float(op1_grad) / op2_value

        else:
            # op1 and op2 may has VariableExploit
            # logging.error(
            #  "Not support complex formula which has divided by VariableExploit")
            # raise NotImplementedError

            op1_grad = self._op1.grad(partial_derivative_opname)
            op2_grad = self._op2.grad(partial_derivative_opname)

            if op2_value != 0:
                # Quotient rule, refer to https://en.wikipedia.org/wiki/Quotient_rule
                result = (op1_grad * op2_value - op1_value * op2_grad) / math.pow(
                    op2_value, 2
                )
            else:
                # TODO: Compute when division by zero
                raise NotImplementedError

        return result


class GlobalVariablesInitializerExploit(Exploit):
    def __init__(self, name="GlobalVariablesInitializer"):
        super(GlobalVariablesInitializerExploit, self).__init__(name)

        self._graph = graph.get_default_graph()
        self._graph.add_to_graph(self)

    def forward(self):
        pass

    def grad(self):
        raise NotImplementedError


class LocalVariablesInitializerExploit(Exploit):
    def __init__(self, name="LocalVariablesInitializer"):
        super(LocalVariablesInitializerExploit, self).__init__(name)

        self._graph = graph.get_default_graph()
        self._graph.add_to_graph(self)

    def forward(self):
        pass

    def grad(self):
        raise NotImplementedError


def get_variable(
    name="Variable",
    value=None,
    shape=None,
    dtype=None,
    initializer=None,
    regularizer=None,
    reuse=None,
    trainable=True,
):
    # TODO: Support default graph only
    _graph = graph.get_default_graph()

    if name in _graph.get_name_op_map():
        return _graph.get_name_op_map()[name]
    else:
        return VariableExploit(value=value, name=name)
